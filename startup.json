{
  "aliases": null,
  "anti_patterns": [
    "Trying to read agents/* files (they're symlinked, causes confusion)",
    "Loading all bundles upfront",
    "Reading documentation 'just in case'",
    "Trying to memorize everything before starting",
    "Loading project READMEs you're not working with"
  ],
  "bootstrap": {
    "content": {
      "anti_patterns": [
        {
          "instead": "Always use feature branches",
          "pattern": "Committing directly to main/master",
          "why": "No review process, hard to rollback"
        },
        {
          "instead": "Only restart for deps/config/supervision changes",
          "pattern": "Restarting server for regular code changes",
          "why": "Wastes time, Phoenix reloads automatically"
        },
        {
          "instead": "Always read README first",
          "pattern": "Making changes without reading project README",
          "why": "Miss project-specific context and conventions"
        },
        {
          "instead": "Try 1-2 times, then ask user",
          "pattern": "Continuing when stuck instead of asking",
          "why": "Wastes cycles on wrong approach"
        },
        {
          "instead": "Log each guideline application with mix bundles.track",
          "pattern": "Not tracking guideline usage",
          "why": "Prevents bundle optimization"
        },
        {
          "instead": "Use 'agents/bundles/*.json' or verify with 'ls -la agents'",
          "pattern": "Looking for agents directory in wrong location",
          "why": "It's a symlink to ~/dev/agents, not a real directory"
        },
        {
          "instead": "Read startup.json which has everything bundled",
          "pattern": "Reading agents/* files at startup",
          "why": "Symlink causes confusion, content already in startup.json"
        }
      ],
      "bootstrap_workflow": {
        "new_project_session": [
          "1. Read startup.json (contains README, bootstrap, aliases bundled inline)",
          "2. DO NOT try to read agents/* files - already bundled in startup.json",
          "3. Check current git branch",
          "3. Check current git branch",
          "4. Load this bootstrap bundle for core rules",
          "5. Initialize tracking: mix bundles.track init <project> <branch> bootstrap",
          "6. Ask user what task to work on",
          "7. Load additional bundles as needed for task",
          "8. Log guideline usage throughout work",
          "9. End session: mix bundles.track summary"
        ]
      },
      "bundle": "bootstrap",
      "decision_trees": {
        "when_to_ask": [
          {
            "no": "Ask for clarification",
            "question": "Are requirements clear?",
            "yes": "next_question"
          },
          {
            "no": "next_question",
            "question": "Is this a common pattern with established solution?",
            "yes": "Proceed with implementation"
          },
          {
            "no": "Proceed with best solution",
            "question": "Are there multiple valid approaches?",
            "yes": "Ask which approach preferred"
          }
        ],
        "when_to_restart": [
          {
            "no": "next_question",
            "question": "Did you modify mix.exs dependencies?",
            "yes": "Restart with reason: deps_changed"
          },
          {
            "no": "next_question",
            "question": "Did you modify config files?",
            "yes": "Restart with reason: config_changed"
          },
          {
            "no": "Do NOT restart - Phoenix reloads automatically",
            "question": "Did you modify supervision tree?",
            "yes": "Restart with reason: supervision_tree_changed"
          }
        ]
      },
      "description": "Minimal guidelines for new projects - just the essentials",
      "includes": [
        "GUIDELINES.md (core only)",
        "AGENTS.md"
      ],
      "patterns": {
        "git_workflow": {
          "start_task": [
            "Read project README",
            "Check current branch: git branch --show-current",
            "Create feature branch: git checkout -b feature/description",
            "Log: mix bundles.track ref git_feature_branch \"Starting task\"",
            "Make changes with frequent commits",
            "Push branch: git push origin feature/description",
            "Wait for user approval before merging"
          ]
        },
        "verification_checklist": {
          "before_completing": [
            "Run tests: mix test",
            "Run precommit: mix precommit",
            "Verify UI changes in browser (if applicable)",
            "Check for errors in logs",
            "Ensure all files are committed",
            "Log: mix bundles.track summary"
          ]
        }
      },
      "quick_reference": {
        "agents_directory": {
          "access": "Both relative (agents/) and absolute (~/dev/agents/) paths work",
          "bundles": "agents/bundles/*.json",
          "location": "~/dev/agents (symlinked as ./agents)",
          "verify": "ls -la agents"
        },
        "available_bundles": {
          "bootstrap": "Core guidelines (you're reading this)",
          "database_work": "Ash resources, migrations, polymorphic relations",
          "dev_auth_bypass": "Development auth bypass for Ash Authentication",
          "navbar_setup": "Complete navbar setup with logo and user menu",
          "ui_work": "LiveView, DaisyUI, Phoenix components"
        },
        "common_commands": {
          "migrate": "mix ecto.migrate",
          "precommit": "mix precommit",
          "reset_db": "mix ecto.reset",
          "server": "mix phx.server",
          "test": "mix test"
        },
        "restart_reasons": [
          "deps_changed",
          "config_changed",
          "supervision_tree_changed"
        ],
        "startup_process": {
          "bundled_content": [
            "README",
            "bootstrap guidelines",
            "aliases",
            "workflow"
          ],
          "never_read": [
            "agents/bundles/*.json",
            "agents/ALIASES.md",
            "README.md separately"
          ],
          "read": "startup.json only",
          "rebuild_command": "mix startup.build"
        },
        "tracking_commands": {
          "end_session": "mix bundles.track summary",
          "log_usage": "mix bundles.track ref <guideline_id> \"context\""
        }
      },
      "rules": [
        {
          "category": "meta",
          "context": "All projects share the same agents directory via symlink",
          "examples": {
            "access_bundles": [
              "cat agents/bundles/bootstrap.json",
              "File.read!(\"agents/bundles/bootstrap.json\")",
              "cat ~/dev/agents/bundles/bootstrap.json"
            ],
            "reads_as": "agents -> /Users/vince/dev/agents",
            "verify_symlink": "ls -la agents"
          },
          "id": "agents_directory_location",
          "pattern": {
            "absolute_path": "~/dev/agents/bundles/*.json",
            "both_work": "Use either relative or absolute paths",
            "relative_path": "agents/bundles/*.json"
          },
          "priority": "critical",
          "rule": "The agents directory is a symlink to ~/dev/agents"
        },
        {
          "category": "meta",
          "context": "Never try to read agents/* files at startup - everything is already in startup.json",
          "examples": {
            "correct_startup": [
              "Read startup.json (has README, bootstrap, aliases bundled)",
              "Access content via: startup[\"readme\"][\"content\"]",
              "Access bootstrap via: startup[\"bootstrap\"][\"content\"]"
            ],
            "incorrect_startup": [
              "Read README.md separately",
              "Try to read agents/bundles/bootstrap.json",
              "Try to read agents/ALIASES.md"
            ]
          },
          "id": "startup_json_bundled",
          "pattern": {
            "end_of_session": "Always run: mix startup.build",
            "next_session_gets": "Fully bundled startup.json with all content",
            "workflow_step": "Step 7 in workflow: mix startup.build"
          },
          "priority": "critical",
          "rationale": "Avoids symlink confusion and failed file reads",
          "rule": "startup.json contains all startup content bundled inline"
        },
        {
          "category": "meta",
          "context": "Log when you actively apply a guideline, not just read it. This data improves bundle optimization.",
          "examples": {
            "good": [
              "mix bundles.track ref git_feature_branch \"Creating feature branch for user profiles\"",
              "mix bundles.track ref daisyui_philosophy \"Choosing semantic button classes\""
            ]
          },
          "id": "usage_tracking",
          "pattern": "mix bundles.track ref <guideline_id> \"<context>\"",
          "priority": "high",
          "rule": "Log guideline usage for optimization"
        },
        {
          "category": "git",
          "examples": {
            "bad": "git commit -m 'add feature' (on main)",
            "good": "git checkout -b feature/user-profiles"
          },
          "id": "git_feature_branch",
          "priority": "critical",
          "rule": "Always work on feature branches, never on master/main"
        },
        {
          "category": "git",
          "context": "Explain 'why' not just 'what'",
          "id": "git_commit_frequently",
          "priority": "high",
          "rule": "Make frequent commits with clear messages"
        },
        {
          "category": "git",
          "id": "git_never_merge",
          "priority": "critical",
          "rule": "Never merge without user approval"
        },
        {
          "category": "git",
          "id": "git_never_delete_branches",
          "priority": "critical",
          "rule": "Never delete branches without approval"
        },
        {
          "category": "verification",
          "context": "If available in project",
          "id": "verify_before_complete",
          "priority": "high",
          "rule": "Run mix precommit before marking work complete"
        },
        {
          "category": "verification",
          "id": "test_appropriately",
          "priority": "high",
          "rule": "Test changes appropriately (code tests, UI verification)"
        },
        {
          "category": "communication",
          "context": "Don't waste cycles guessing",
          "id": "ask_when_stuck",
          "priority": "high",
          "rule": "Take 1-2 fix attempts, then ask user if stuck"
        },
        {
          "category": "communication",
          "context": "No unnecessary preamble or postamble",
          "id": "concise_responses",
          "priority": "medium",
          "rule": "Keep responses concise (1-3 sentences when possible)"
        },
        {
          "category": "communication",
          "id": "ask_vs_proceed",
          "priority": "high",
          "rule": "Ask when requirements unclear, proceed when clear"
        },
        {
          "category": "code_quality",
          "context": "Avoid :httpoison, :tesla, :httpc",
          "id": "use_req_library",
          "priority": "medium",
          "rule": "Use :req library for HTTP requests"
        },
        {
          "category": "code_quality",
          "id": "daisyui_for_components",
          "priority": "high",
          "rule": "Use DaisyUI for components, Tailwind for layout"
        },
        {
          "category": "code_quality",
          "context": "Only restart for: deps_changed, config_changed, supervision_tree_changed",
          "id": "never_restart_unnecessarily",
          "priority": "high",
          "rule": "Never restart server for regular changes (Phoenix reloads automatically)"
        }
      ],
      "usage_tracking": {
        "enabled": true,
        "instructions": "When you apply a guideline during work, log it immediately using: `mix bundles.track ref <guideline_id> \"<brief context>\"`. This helps optimize future sessions."
      },
      "version": "1.5.0"
    },
    "purpose": "Minimal core rules - git workflow, verification, tracking"
  },
  "description": "Startup configuration for Maestro AI sessions - all content bundled",
  "generated_at": "2025-10-29T04:18:31.447305Z",
  "philosophy": "Load less, reference more. Read what you need when you need it. Everything you need to start is in this file.",
  "readme": {
    "content": "# Maestro\n\nProject orchestration and agent coordination hub.\n\n## Project Tasks\n\n### Current: Agent Startup Optimization\n\n**The Problem:** AI agents spend enormous amounts of time, money, and tokens loading all guidelines at session start. We need to solve this by loading only what's needed for specific tasks.\n\n**The Solution:**\n- **Maestro** (this project): Reads entire `agents/` directory to have full context for coordinating work\n- **Other projects**: Load minimal essential guidelines at startup\n- **Task-specific loading**: When we assign a task to another project, Maestro tells them exactly what guidelines they need to read\n- **Usage tracking**: Track which guidelines agents actually reference during work to optimize future sessions\n\n**How it works:**\n1. Maestro plans tasks for other projects here\n2. Maestro writes the task with specific reading requirements to the project's CHANGELOG\n3. That project's agent starts up, reads minimal guidelines + task-specific ones\n4. Agent logs which guidelines were actually used (server log style)\n5. We analyze logs to optimize what to load by default\n\n**Current status:**\n- ✅ Maestro reads everything (agents/ directory)\n- ✅ Other project startup files created (minimal loading)\n- ⚠️ GUIDELINE_USAGE_TRACKER exists but not being used as intended\n- 🔄 Need to implement usage logging (agent-oriented, like server logs)\n- 🔄 Need to test with other projects loading minimal set\n\n### Completed: CSS Linter Integration\n\n**Branch:** feature/css-linter\n\n**Goal:** Move Tailwind analysis UI from Maestro to css_linter tool, making it reusable across all projects.\n\n**Status:** ✅ Working, needs migration for full functionality\n\n**What was done:**\n- Copied TailwindAnalysisLive to css_linter package\n- Refactored to be repo-agnostic and mountable from any app\n- Added LiveTable dependency to css_linter\n- Configured and mounted in Maestro (separate scope to avoid namespace collision)\n\n**Remaining:**\n- Run migration for css_class_usage table\n- Test UI functionality\n- Remove old Maestro-specific analysis files\n- Document web UI usage in css_linter\n\n### Access Points\n\n- **Web App**: http://localhost:4004\n- **Live Debugger**: http://localhost:4012\n\n## Orchestration Features\n\nCurrent features:\n- **Project Dashboard**: View status of all projects\n- **Real-time Monitoring**: Track which projects are running (ProjectMonitor GenServer checks TCP ports every 10s)\n- **Guideline Browser**: Visual tree of all agent guidelines\n- **LiveTable Integration**: Uses vintrepid/live_table fork with DaisyUI styling\n\nPlanned features:\n- **Task Planning**: Create and assign tasks to other projects\n- **Usage Analytics**: Track which guidelines are actually referenced\n- **Smart Loading**: Recommend minimal guideline set based on task type\n- **Multi-Project Commands**: Start/stop multiple projects\n- **Log Aggregation**: View logs from all projects\n- **Environment Management**: Manage .env files across projects\n\n## Technical Details\n\n### Project Monitoring\n- ProjectMonitor GenServer checks TCP ports every 10s\n- LiveView updates UI every 5s\n- Real-time status indicators (green=running, red=stopped)\n\n### Dashboard\n- Uses LiveTable component from vintrepid/live_table fork\n- DaisyUI styling with table-pin-rows for fixed headers\n- Sortable and searchable project listing\n\n### Guideline Browser\n- Visual tree view of entire agents directory\n- Helps agents understand available documentation\n- Checkbox tracking (UI-only, not persisted)\n\n### Database\n- Uses Ash Framework with PostgreSQL\n- Ecto for css_linter integration (Ash not compatible with LiveTable)\n- Seeds include 6 projects: Ready, Calvin, SanJuan, new_project, Maestro, np\n\n## Development Setup\n\n### Prerequisites\n\n- Elixir 1.18.3\n- PostgreSQL running at localhost\n- Erlang/OTP 27\n\n### Getting Started\n\n```bash\ncd ~/dev/maestro\nsource .env\nmix deps.get\nmix ecto.setup\nmix phx.server\n```\n\nVisit: http://localhost:4004\n\n### Database Commands\n\n```bash\nmix ecto.create\nmix ecto.migrate\nmix ecto.reset\n```\n\n## Project Structure\n\n```\nlib/\n├── maestro/\n│   └── ops/              # Project management\n├── maestro_web/\n│   ├── components/       # Guideline viewer, etc\n│   └── live/            # Dashboard, project detail\npriv/\n├── repo/\n│   ├── migrations/\n│   └── seeds.exs\n```\n\n## Other Projects Tracked\n\n- **Ready**: Web 4000, Debugger 4008\n- **new_project**: Web 4001, Debugger 4009\n- **Calvin**: Web 4002, Debugger 4010\n- **SanJuan**: Web 4003, Debugger 4011\n- **Circle**: Web 4015, Debugger 4016\n",
    "purpose": "Know who you are - project identity, purpose, ports"
  },
  "session": "maestro_startup",
  "task": {
    "content": "# Current State: Task Runner Pattern Established\n\n## This Session (Session 2): Critical Learning Captured\n\n### 🚨 THE BREAKTHROUGH: Task Runner Workflow 🚨\n\nWe established the complete pattern for agent-user communication through tasks.\n\n**The Pattern:**\n1. User clicks \"Run Task\" button → Task becomes active\n2. User says \"run\" → Agent executes\n3. Agent follows workflow:\n   - Format description markdown\n   - Read request (description field)\n   - Plan and execute\n   - Document completion (notes field)\n   - Mark complete if done\n   - Learn and capture patterns\n\n**Key Files:**\n- `TASK_RUNNER_WORKFLOW.md` - Complete workflow guide\n- `WHAT_WENT_WRONG.md` - Session 2 learning (ALWAYS USE ASH)\n- `bootstrap/GUIDELINES.md` - Core principle added (front and center)\n- `current_task.json` - Crash recovery state\n\n### What Was Completed\n\n#### Task #20: Better Agent Training\n**Request:** \"Cleanup this markdown\"\n**Response:** \n- ✅ Learned the hard way: ALWAYS USE ASH (not browser_eval)\n- ✅ Established Task Runner pattern\n- ✅ Updated core guidelines (Ash principle front and center)\n- ✅ Documented in WHAT_WENT_WRONG.md\n- ✅ Updated current_task.json for crash recovery\n\n**Critical Learning:** Tried to update task via browser_eval (failed). User corrected: \"Use Ash framework.\" Immediate success with `Task.update(task, %{field: value})`.\n\n#### Task #21: More Maestro Mix Tasks\n**Request:** \"Write scripts for yourself. I want to see a lot less shell commands.\"\n**Response:**\n- ✅ Created 4 new mix tasks\n- ✅ `mix maestro.task.read TASK_ID`\n- ✅ `mix maestro.task.update TASK_ID FIELD VALUE`\n- ✅ `mix maestro.task.list [OPTIONS]`\n- ✅ `mix agents.update FILE MESSAGE`\n- ✅ Marked complete with detailed notes\n\n### Infrastructure Now Available\n\n**Mix Tasks for Future Sessions:**\n```bash\nmix maestro.task.read 20           # Read task details\nmix maestro.task.update 20 status done  # Update via Ash\nmix maestro.task.list --status todo     # List/filter tasks\nmix agents.update FILE MESSAGE     # Update agents repo\n```\n\n**Documentation:**\n- `TASK_RUNNER_WORKFLOW.md` - Step-by-step execution pattern\n- `WHAT_WENT_WRONG.md` - Session 1 & 2 learnings\n- `bootstrap/GUIDELINES.md` - ALWAYS USE ASH (first principle)\n- `current_task.json` - Session state for crash recovery\n- `USAGE_RULES.md` - All library patterns (38KB)\n\n**Agents Repo Updated:**\n- `bootstrap/GUIDELINES.md` - Added Ash principle as #1 core principle\n- Committed and pushed to origin/main\n- Available to ALL projects now\n\n### The Golden Rule (Learned Session 2)\n\n**🚨 ALWAYS USE ASH FOR DATA MODIFICATIONS 🚨**\n\n```elixir\n# Read\ntask = Maestro.Ops.Task.by_id!(task_id)\n\n# Update (THE CORRECT WAY)\n{:ok, updated} = Maestro.Ops.Task.update(task, %{\n  description: cleaned_description,\n  notes: completion_notes,\n  status: :done\n})\n```\n\n**NOT:**\n- ❌ browser_eval to manipulate UI\n- ❌ Direct SQL updates\n- ❌ LiveView assign modifications\n\n**Why:** Ash runs validations, calculations, authorization, hooks. Data actually persists.\n\n## Next Session Priorities\n\n### If User Clicks \"Run Task\" and Says \"run\"\n\n1. **Read this file** - Understand current state\n2. **Read TASK_RUNNER_WORKFLOW.md** - Follow the pattern\n3. **Read the task's description** - That's the request\n4. **Format description markdown** - Make it pretty\n5. **Execute the work** - Ask questions if needed\n6. **Write completion to notes** - Using Ash\n7. **Mark complete** - If appropriate\n8. **Learn** - Capture patterns\n\n### Available Tools\n\n```bash\nmix maestro.task.read TASK_ID      # Read task\nmix maestro.task.update TASK_ID notes \"...\" # Update via Ash\nmix maestro.task.list --status todo        # List tasks\nmix agents.update FILE MESSAGE     # Update agents repo\nmix bundles.track ref ID \"context\" # Log usage\nmix startup.build                  # Update startup.json\n```\n\n### Outstanding Tasks\n\nCheck active tasks:\n```bash\nmix maestro.task.list --status todo\n```\n\nOr look at Maestro UI: http://localhost:4004/tasks\n\n## Session Statistics\n\n**Session 2:**\n- Tasks completed: 2 (Task #20, Task #21)\n- Critical learning: ALWAYS USE ASH\n- Mix tasks created: 4\n- Guidelines updated: 3 files\n- Agents repo commits: 1\n- Guideline usage logged: 5 references\n\n**Knowledge captured:**\n- Task Runner Workflow pattern\n- Ash-first principle (front and center)\n- Mix tasks for common operations\n- Crash recovery state maintained\n\n## For Future You\n\n**When you start:**\n1. Read `startup.json` - Everything bundled\n2. Read `current_task.json` - Session state\n3. Read `TASK_RUNNER_WORKFLOW.md` - How to execute tasks\n4. Check for active task: Look at AppState or UI\n\n**When you work:**\n- ALWAYS use Ash for data modifications\n- Format description markdown\n- Document completion in notes\n- Mark complete if appropriate\n- Learn and capture patterns\n\n**When you finish:**\n```bash\nmix startup.build  # Update for next agent\ngit add . && git commit -m \"Session summary\"\ngit push origin feature/task-runner\n```\n\n**If you crash:**\nRead `current_task.json` first - it has everything you need to continue.\n\n## The Pattern That Works\n\n**Description → Notes via Ash**\n\n```elixir\n# 1. Read\ntask = Maestro.Ops.Task.by_id!(task_id)\nIO.puts(task.description)  # The request\n\n# 2. Do work\nresult = do_the_work()\n\n# 3. Write response\n{:ok, updated} = Maestro.Ops.Task.update(task, %{\n  notes: \"## Completion Note\\n\\nWhat I did...\",\n  status: :done  # if complete\n})\n```\n\nThis is the way. 🎯\n",
    "purpose": "Current ongoing task and context"
  },
  "usage_rules": {
    "content": "<!-- usage-rules-start -->\n<!-- usage-rules-header -->\n# Usage Rules\n\n**IMPORTANT**: Consult these usage rules early and often when working with the packages listed below.\nBefore attempting to use any of these packages or to discover if you should use them, review their\nusage rules to understand the correct patterns, conventions, and best practices.\n<!-- usage-rules-header-end -->\n\n<!-- phoenix:ecto-start -->\n## phoenix:ecto usage\n## Ecto Guidelines\n\n- **Always** preload Ecto associations in queries when they'll be accessed in templates, ie a message that needs to reference the `message.user.email`\n- Remember `import Ecto.Query` and other supporting modules when you write `seeds.exs`\n- `Ecto.Schema` fields always use the `:string` type, even for `:text`, columns, ie: `field :name, :string`\n- `Ecto.Changeset.validate_number/2` **DOES NOT SUPPORT the `:allow_nil` option**. By default, Ecto validations only run if a change for the given field exists and the change value is not nil, so such as option is never needed\n- You **must** use `Ecto.Changeset.get_field(changeset, :field)` to access changeset fields\n- Fields which are set programatically, such as `user_id`, must not be listed in `cast` calls or similar for security purposes. Instead they must be explicitly set when creating the struct\n\n<!-- phoenix:ecto-end -->\n<!-- phoenix:elixir-start -->\n## phoenix:elixir usage\n## Elixir guidelines\n\n- Elixir lists **do not support index based access via the access syntax**\n\n  **Never do this (invalid)**:\n\n      i = 0\n      mylist = [\"blue\", \"green\"]\n      mylist[i]\n\n  Instead, **always** use `Enum.at`, pattern matching, or `List` for index based list access, ie:\n\n      i = 0\n      mylist = [\"blue\", \"green\"]\n      Enum.at(mylist, i)\n\n- Elixir variables are immutable, but can be rebound, so for block expressions like `if`, `case`, `cond`, etc\n  you *must* bind the result of the expression to a variable if you want to use it and you CANNOT rebind the result inside the expression, ie:\n\n      # INVALID: we are rebinding inside the `if` and the result never gets assigned\n      if connected?(socket) do\n        socket = assign(socket, :val, val)\n      end\n\n      # VALID: we rebind the result of the `if` to a new variable\n      socket =\n        if connected?(socket) do\n          assign(socket, :val, val)\n        end\n\n- **Never** nest multiple modules in the same file as it can cause cyclic dependencies and compilation errors\n- **Never** use map access syntax (`changeset[:field]`) on structs as they do not implement the Access behaviour by default. For regular structs, you **must** access the fields directly, such as `my_struct.field` or use higher level APIs that are available on the struct if they exist, `Ecto.Changeset.get_field/2` for changesets\n- Elixir's standard library has everything necessary for date and time manipulation. Familiarize yourself with the common `Time`, `Date`, `DateTime`, and `Calendar` interfaces by accessing their documentation as necessary. **Never** install additional dependencies unless asked or for date/time parsing (which you can use the `date_time_parser` package)\n- Don't use `String.to_atom/1` on user input (memory leak risk)\n- Predicate function names should not start with `is_` and should end in a question mark. Names like `is_thing` should be reserved for guards\n- Elixir's builtin OTP primitives like `DynamicSupervisor` and `Registry`, require names in the child spec, such as `{DynamicSupervisor, name: MyApp.MyDynamicSup}`, then you can use `DynamicSupervisor.start_child(MyApp.MyDynamicSup, child_spec)`\n- Use `Task.async_stream(collection, callback, options)` for concurrent enumeration with back-pressure. The majority of times you will want to pass `timeout: :infinity` as option\n\n## Mix guidelines\n\n- Read the docs and options before using tasks (by using `mix help task_name`)\n- To debug test failures, run tests in a specific file with `mix test test/my_test.exs` or run all previously failed tests with `mix test --failed`\n- `mix deps.clean --all` is **almost never needed**. **Avoid** using it unless you have good reason\n\n<!-- phoenix:elixir-end -->\n<!-- phoenix:html-start -->\n## phoenix:html usage\n## Phoenix HTML guidelines\n\n- Phoenix templates **always** use `~H` or .html.heex files (known as HEEx), **never** use `~E`\n- **Always** use the imported `Phoenix.Component.form/1` and `Phoenix.Component.inputs_for/1` function to build forms. **Never** use `Phoenix.HTML.form_for` or `Phoenix.HTML.inputs_for` as they are outdated\n- When building forms **always** use the already imported `Phoenix.Component.to_form/2` (`assign(socket, form: to_form(...))` and `<.form for={@form} id=\"msg-form\">`), then access those forms in the template via `@form[:field]`\n- **Always** add unique DOM IDs to key elements (like forms, buttons, etc) when writing templates, these IDs can later be used in tests (`<.form for={@form} id=\"product-form\">`)\n- For \"app wide\" template imports, you can import/alias into the `my_app_web.ex`'s `html_helpers` block, so they will be available to all LiveViews, LiveComponent's, and all modules that do `use MyAppWeb, :html` (replace \"my_app\" by the actual app name)\n\n- Elixir supports `if/else` but **does NOT support `if/else if` or `if/elsif`. **Never use `else if` or `elseif` in Elixir**, **always** use `cond` or `case` for multiple conditionals.\n\n  **Never do this (invalid)**:\n\n      <%= if condition do %>\n        ...\n      <% else if other_condition %>\n        ...\n      <% end %>\n\n  Instead **always** do this:\n\n      <%= cond do %>\n        <% condition -> %>\n          ...\n        <% condition2 -> %>\n          ...\n        <% true -> %>\n          ...\n      <% end %>\n\n- HEEx require special tag annotation if you want to insert literal curly's like `{` or `}`. If you want to show a textual code snippet on the page in a `<pre>` or `<code>` block you *must* annotate the parent tag with `phx-no-curly-interpolation`:\n\n      <code phx-no-curly-interpolation>\n        let obj = {key: \"val\"}\n      </code>\n\n  Within `phx-no-curly-interpolation` annotated tags, you can use `{` and `}` without escaping them, and dynamic Elixir expressions can still be used with `<%= ... %>` syntax\n\n- HEEx class attrs support lists, but you must **always** use list `[...]` syntax. You can use the class list syntax to conditionally add classes, **always do this for multiple class values**:\n\n      <a class={[\n        \"px-2 text-white\",\n        @some_flag && \"py-5\",\n        if(@other_condition, do: \"border-red-500\", else: \"border-blue-100\"),\n        ...\n      ]}>Text</a>\n\n  and **always** wrap `if`'s inside `{...}` expressions with parens, like done above (`if(@other_condition, do: \"...\", else: \"...\")`)\n\n  and **never** do this, since it's invalid (note the missing `[` and `]`):\n\n      <a class={\n        \"px-2 text-white\",\n        @some_flag && \"py-5\"\n      }> ...\n      => Raises compile syntax error on invalid HEEx attr syntax\n\n- **Never** use `<% Enum.each %>` or non-for comprehensions for generating template content, instead **always** use `<%= for item <- @collection do %>`\n- HEEx HTML comments use `<%!-- comment --%>`. **Always** use the HEEx HTML comment syntax for template comments (`<%!-- comment --%>`)\n- HEEx allows interpolation via `{...}` and `<%= ... %>`, but the `<%= %>` **only** works within tag bodies. **Always** use the `{...}` syntax for interpolation within tag attributes, and for interpolation of values within tag bodies. **Always** interpolate block constructs (if, cond, case, for) within tag bodies using `<%= ... %>`.\n\n  **Always** do this:\n\n      <div id={@id}>\n        {@my_assign}\n        <%= if @some_block_condition do %>\n          {@another_assign}\n        <% end %>\n      </div>\n\n  and **Never** do this – the program will terminate with a syntax error:\n\n      <%!-- THIS IS INVALID NEVER EVER DO THIS --%>\n      <div id=\"<%= @invalid_interpolation %>\">\n        {if @invalid_block_construct do}\n        {end}\n      </div>\n\n<!-- phoenix:html-end -->\n<!-- phoenix:liveview-start -->\n## phoenix:liveview usage\n## Phoenix LiveView guidelines\n\n- **Never** use the deprecated `live_redirect` and `live_patch` functions, instead **always** use the `<.link navigate={href}>` and  `<.link patch={href}>` in templates, and `push_navigate` and `push_patch` functions LiveViews\n- **Avoid LiveComponent's** unless you have a strong, specific need for them\n- LiveViews should be named like `AppWeb.WeatherLive`, with a `Live` suffix. When you go to add LiveView routes to the router, the default `:browser` scope is **already aliased** with the `AppWeb` module, so you can just do `live \"/weather\", WeatherLive`\n- Remember anytime you use `phx-hook=\"MyHook\"` and that js hook manages its own DOM, you **must** also set the `phx-update=\"ignore\"` attribute\n- **Never** write embedded `<script>` tags in HEEx. Instead always write your scripts and hooks in the `assets/js` directory and integrate them with the `assets/js/app.js` file\n\n### LiveView streams\n\n- **Always** use LiveView streams for collections for assigning regular lists to avoid memory ballooning and runtime termination with the following operations:\n  - basic append of N items - `stream(socket, :messages, [new_msg])`\n  - resetting stream with new items - `stream(socket, :messages, [new_msg], reset: true)` (e.g. for filtering items)\n  - prepend to stream - `stream(socket, :messages, [new_msg], at: -1)`\n  - deleting items - `stream_delete(socket, :messages, msg)`\n\n- When using the `stream/3` interfaces in the LiveView, the LiveView template must 1) always set `phx-update=\"stream\"` on the parent element, with a DOM id on the parent element like `id=\"messages\"` and 2) consume the `@streams.stream_name` collection and use the id as the DOM id for each child. For a call like `stream(socket, :messages, [new_msg])` in the LiveView, the template would be:\n\n      <div id=\"messages\" phx-update=\"stream\">\n        <div :for={{id, msg} <- @streams.messages} id={id}>\n          {msg.text}\n        </div>\n      </div>\n\n- LiveView streams are *not* enumerable, so you cannot use `Enum.filter/2` or `Enum.reject/2` on them. Instead, if you want to filter, prune, or refresh a list of items on the UI, you **must refetch the data and re-stream the entire stream collection, passing reset: true**:\n\n      def handle_event(\"filter\", %{\"filter\" => filter}, socket) do\n        # re-fetch the messages based on the filter\n        messages = list_messages(filter)\n\n        {:noreply,\n        socket\n        |> assign(:messages_empty?, messages == [])\n        # reset the stream with the new messages\n        |> stream(:messages, messages, reset: true)}\n      end\n\n- LiveView streams *do not support counting or empty states*. If you need to display a count, you must track it using a separate assign. For empty states, you can use Tailwind classes:\n\n      <div id=\"tasks\" phx-update=\"stream\">\n        <div class=\"hidden only:block\">No tasks yet</div>\n        <div :for={{id, task} <- @stream.tasks} id={id}>\n          {task.name}\n        </div>\n      </div>\n\n  The above only works if the empty state is the only HTML block alongside the stream for-comprehension.\n\n- **Never** use the deprecated `phx-update=\"append\"` or `phx-update=\"prepend\"` for collections\n\n### LiveView tests\n\n- `Phoenix.LiveViewTest` module and `LazyHTML` (included) for making your assertions\n- Form tests are driven by `Phoenix.LiveViewTest`'s `render_submit/2` and `render_change/2` functions\n- Come up with a step-by-step test plan that splits major test cases into small, isolated files. You may start with simpler tests that verify content exists, gradually add interaction tests\n- **Always reference the key element IDs you added in the LiveView templates in your tests** for `Phoenix.LiveViewTest` functions like `element/2`, `has_element/2`, selectors, etc\n- **Never** tests again raw HTML, **always** use `element/2`, `has_element/2`, and similar: `assert has_element?(view, \"#my-form\")`\n- Instead of relying on testing text content, which can change, favor testing for the presence of key elements\n- Focus on testing outcomes rather than implementation details\n- Be aware that `Phoenix.Component` functions like `<.form>` might produce different HTML than expected. Test against the output HTML structure, not your mental model of what you expect it to be\n- When facing test failures with element selectors, add debug statements to print the actual HTML, but use `LazyHTML` selectors to limit the output, ie:\n\n      html = render(view)\n      document = LazyHTML.from_fragment(html)\n      matches = LazyHTML.filter(document, \"your-complex-selector\")\n      IO.inspect(matches, label: \"Matches\")\n\n### Form handling\n\n#### Creating a form from params\n\nIf you want to create a form based on `handle_event` params:\n\n    def handle_event(\"submitted\", params, socket) do\n      {:noreply, assign(socket, form: to_form(params))}\n    end\n\nWhen you pass a map to `to_form/1`, it assumes said map contains the form params, which are expected to have string keys.\n\nYou can also specify a name to nest the params:\n\n    def handle_event(\"submitted\", %{\"user\" => user_params}, socket) do\n      {:noreply, assign(socket, form: to_form(user_params, as: :user))}\n    end\n\n#### Creating a form from changesets\n\nWhen using changesets, the underlying data, form params, and errors are retrieved from it. The `:as` option is automatically computed too. E.g. if you have a user schema:\n\n    defmodule MyApp.Users.User do\n      use Ecto.Schema\n      ...\n    end\n\nAnd then you create a changeset that you pass to `to_form`:\n\n    %MyApp.Users.User{}\n    |> Ecto.Changeset.change()\n    |> to_form()\n\nOnce the form is submitted, the params will be available under `%{\"user\" => user_params}`.\n\nIn the template, the form form assign can be passed to the `<.form>` function component:\n\n    <.form for={@form} id=\"todo-form\" phx-change=\"validate\" phx-submit=\"save\">\n      <.input field={@form[:field]} type=\"text\" />\n    </.form>\n\nAlways give the form an explicit, unique DOM ID, like `id=\"todo-form\"`.\n\n#### Avoiding form errors\n\n**Always** use a form assigned via `to_form/2` in the LiveView, and the `<.input>` component in the template. In the template **always access forms this**:\n\n    <%!-- ALWAYS do this (valid) --%>\n    <.form for={@form} id=\"my-form\">\n      <.input field={@form[:field]} type=\"text\" />\n    </.form>\n\nAnd **never** do this:\n\n    <%!-- NEVER do this (invalid) --%>\n    <.form for={@changeset} id=\"my-form\">\n      <.input field={@changeset[:field]} type=\"text\" />\n    </.form>\n\n- You are FORBIDDEN from accessing the changeset in the template as it will cause errors\n- **Never** use `<.form let={f} ...>` in the template, instead **always use `<.form for={@form} ...>`**, then drive all form references from the form assign as in `@form[:field]`. The UI should **always** be driven by a `to_form/2` assigned in the LiveView module that is derived from a changeset\n\n<!-- phoenix:liveview-end -->\n<!-- phoenix:phoenix-start -->\n## phoenix:phoenix usage\n## Phoenix guidelines\n\n- Remember Phoenix router `scope` blocks include an optional alias which is prefixed for all routes within the scope. **Always** be mindful of this when creating routes within a scope to avoid duplicate module prefixes.\n\n- You **never** need to create your own `alias` for route definitions! The `scope` provides the alias, ie:\n\n      scope \"/admin\", AppWeb.Admin do\n        pipe_through :browser\n\n        live \"/users\", UserLive, :index\n      end\n\n  the UserLive route would point to the `AppWeb.Admin.UserLive` module\n\n- `Phoenix.View` no longer is needed or included with Phoenix, don't use it\n\n<!-- phoenix:phoenix-end -->\n<!-- ash_phoenix-start -->\n## ash_phoenix usage\n_Utilities for integrating Ash and Phoenix_\n\n[ash_phoenix usage rules](deps/ash_phoenix/usage-rules.md)\n<!-- ash_phoenix-end -->\n<!-- ash-start -->\n## ash usage\n_A declarative, extensible framework for building Elixir applications._\n\n[ash usage rules](deps/ash/usage-rules.md)\n<!-- ash-end -->\n<!-- ash_authentication-start -->\n## ash_authentication usage\n_Authentication extension for the Ash Framework._\n\n[ash_authentication usage rules](deps/ash_authentication/usage-rules.md)\n<!-- ash_authentication-end -->\n<!-- usage_rules-start -->\n## usage_rules usage\n_A dev tool for Elixir projects to gather LLM usage rules from dependencies_\n\n## Using Usage Rules\n\nMany packages have usage rules, which you should *thoroughly* consult before taking any\naction. These usage rules contain guidelines and rules *directly from the package authors*.\nThey are your best source of knowledge for making decisions.\n\n## Modules & functions in the current app and dependencies\n\nWhen looking for docs for modules & functions that are dependencies of the current project,\nor for Elixir itself, use `mix usage_rules.docs`\n\n```\n# Search a whole module\nmix usage_rules.docs Enum\n\n# Search a specific function\nmix usage_rules.docs Enum.zip\n\n# Search a specific function & arity\nmix usage_rules.docs Enum.zip/1\n```\n\n\n## Searching Documentation\n\nYou should also consult the documentation of any tools you are using, early and often. The best \nway to accomplish this is to use the `usage_rules.search_docs` mix task. Once you have\nfound what you are looking for, use the links in the search results to get more detail. For example:\n\n```\n# Search docs for all packages in the current application, including Elixir\nmix usage_rules.search_docs Enum.zip\n\n# Search docs for specific packages\nmix usage_rules.search_docs Req.get -p req\n\n# Search docs for multi-word queries\nmix usage_rules.search_docs \"making requests\" -p req\n\n# Search only in titles (useful for finding specific functions/modules)\nmix usage_rules.search_docs \"Enum.zip\" --query-by title\n```\n\n\n<!-- usage_rules-end -->\n<!-- usage_rules:elixir-start -->\n## usage_rules:elixir usage\n# Elixir Core Usage Rules\n\n## Pattern Matching\n- Use pattern matching over conditional logic when possible\n- Prefer to match on function heads instead of using `if`/`else` or `case` in function bodies\n- `%{}` matches ANY map, not just empty maps. Use `map_size(map) == 0` guard to check for truly empty maps\n\n## Error Handling\n- Use `{:ok, result}` and `{:error, reason}` tuples for operations that can fail\n- Avoid raising exceptions for control flow\n- Use `with` for chaining operations that return `{:ok, _}` or `{:error, _}`\n\n## Common Mistakes to Avoid\n- Elixir has no `return` statement, nor early returns. The last expression in a block is always returned.\n- Don't use `Enum` functions on large collections when `Stream` is more appropriate\n- Avoid nested `case` statements - refactor to a single `case`, `with` or separate functions\n- Don't use `String.to_atom/1` on user input (memory leak risk)\n- Lists and enumerables cannot be indexed with brackets. Use pattern matching or `Enum` functions\n- Prefer `Enum` functions like `Enum.reduce` over recursion\n- When recursion is necessary, prefer to use pattern matching in function heads for base case detection\n- Using the process dictionary is typically a sign of unidiomatic code\n- Only use macros if explicitly requested\n- There are many useful standard library functions, prefer to use them where possible\n\n## Function Design\n- Use guard clauses: `when is_binary(name) and byte_size(name) > 0`\n- Prefer multiple function clauses over complex conditional logic\n- Name functions descriptively: `calculate_total_price/2` not `calc/2`\n- Predicate function names should not start with `is` and should end in a question mark.\n- Names like `is_thing` should be reserved for guards\n\n## Data Structures\n- Use structs over maps when the shape is known: `defstruct [:name, :age]`\n- Prefer keyword lists for options: `[timeout: 5000, retries: 3]`\n- Use maps for dynamic key-value data\n- Prefer to prepend to lists `[new | list]` not `list ++ [new]`\n\n## Mix Tasks\n\n- Use `mix help` to list available mix tasks\n- Use `mix help task_name` to get docs for an individual task\n- Read the docs and options fully before using tasks\n\n## Testing\n- Run tests in a specific file with `mix test test/my_test.exs` and a specific test with the line number `mix test path/to/test.exs:123`\n- Limit the number of failed tests with `mix test --max-failures n`\n- Use `@tag` to tag specific tests, and `mix test --only tag` to run only those tests\n- Use `assert_raise` for testing expected exceptions: `assert_raise ArgumentError, fn -> invalid_function() end`\n- Use `mix help test` to for full documentation on running tests\n\n## Debugging\n\n- Use `dbg/1` to print values while debugging. This will display the formatted value and other relevant information in the console.\n\n<!-- usage_rules:elixir-end -->\n<!-- usage_rules:otp-start -->\n## usage_rules:otp usage\n# OTP Usage Rules\n\n## GenServer Best Practices\n- Keep state simple and serializable\n- Handle all expected messages explicitly\n- Use `handle_continue/2` for post-init work\n- Implement proper cleanup in `terminate/2` when necessary\n\n## Process Communication\n- Use `GenServer.call/3` for synchronous requests expecting replies\n- Use `GenServer.cast/2` for fire-and-forget messages.\n- When in doubt, use `call` over `cast`, to ensure back-pressure\n- Set appropriate timeouts for `call/3` operations\n\n## Fault Tolerance\n- Set up processes such that they can handle crashing and being restarted by supervisors\n- Use `:max_restarts` and `:max_seconds` to prevent restart loops\n\n## Task and Async\n- Use `Task.Supervisor` for better fault tolerance\n- Handle task failures with `Task.yield/2` or `Task.shutdown/2`\n- Set appropriate task timeouts\n- Use `Task.async_stream/3` for concurrent enumeration with back-pressure\n\n<!-- usage_rules:otp-end -->\n<!-- ash_oban-start -->\n## ash_oban usage\n_The extension for integrating Ash resources with Oban._\n\n[ash_oban usage rules](deps/ash_oban/usage-rules.md)\n<!-- ash_oban-end -->\n<!-- ash_ai-start -->\n## ash_ai usage\n_Integrated LLM features for your Ash application._\n\n[ash_ai usage rules](deps/ash_ai/usage-rules.md)\n<!-- ash_ai-end -->\n<!-- igniter-start -->\n## igniter usage\n_A code generation and project patching framework_\n\n[igniter usage rules](deps/igniter/usage-rules.md)\n<!-- igniter-end -->\n<!-- ash_postgres-start -->\n## ash_postgres usage\n_The PostgreSQL data layer for Ash Framework_\n\n[ash_postgres usage rules](deps/ash_postgres/usage-rules.md)\n<!-- ash_postgres-end -->\n<!-- usage-rules-end -->\n\n<!-- maestro_tool-start -->\n## maestro_tool usage\n# MaestroTool Agent Guidelines\n\n## Overview\n\nMaestroTool is a standalone development tool for standardizing Phoenix/LiveView/Ash project configuration.\n\n## Usage\n\n### Installation\n\nAdd to your project's mix.exs:\n\n```elixir\ndef deps do\n  [\n    {:maestro_tool, github: \"vintrepid/maestro_tool\", only: [:dev]}\n  ]\nend\n```\n\n### Available Tasks\n\n#### `mix maestro_tool.project.update`\n\nStandardizes project configuration with:\n- `.env` file with project-specific ports\n- Updated `README.md` with correct information\n- Git remote setup (GitHub)\n- Agents symlink creation\n\n**Options:**\n- `--github-user` - GitHub username (default: vintrepid)\n\n**Example:**\n```bash\nmix maestro_tool.project.update\nmix maestro_tool.project.update --github-user myusername\n```\n\n**Behavior:**\n- Idempotent - safe to run multiple times\n- Won't overwrite existing `.env` files\n- Only updates README if it has default Phoenix content\n- Adds git remote only if missing\n\n## Project Ports\n\nThe tool automatically detects project-specific ports:\n- maestro: 4004/4012\n- circle: 4015/4016\n- ready: 4000/4008\n- calvin: 4002/4010\n- san_juan: 4003/4011\n- new_project: 4001/4009\n- default: 4000/4012\n\n## Development\n\n### Structure\n\n```\nmaestro_tool/\n├── lib/\n│   ├── maestro_tool/\n│   │   └── application.ex\n│   ├── mix/\n│   │   └── tasks/\n│   │       └── maestro_tool.project.update.ex\n│   └── maestro_tool.ex\n├── test/\n├── mix.exs\n├── README.md\n├── CHANGELOG.md\n└── AGENTS.md (this file)\n```\n\n### Adding New Tasks\n\n1. Create new file in `lib/mix/tasks/`\n2. Use `Mix.Task` behavior\n3. Add `@shortdoc` and `@moduledoc`\n4. Namespace with `Mix.Tasks.MaestroTool.*`\n\nExample:\n```elixir\ndefmodule Mix.Tasks.MaestroTool.Analyze do\n  @moduledoc \"\"\"\n  Analyzes project structure.\n  \"\"\"\n  \n  use Mix.Task\n\n  @shortdoc \"Analyze project structure\"\n\n  def run(args) do\n    # Your logic here\n  end\nend\n```\n\n### Testing\n\n```bash\nmix test\n```\n\n### Release Process\n\n1. Update CHANGELOG.md\n2. Bump version in mix.exs\n3. Commit changes\n4. Tag release: `git tag v0.X.0`\n5. Push: `git push --tags`\n\n## Best Practices\n\n- Keep dependencies minimal\n- Make tasks idempotent\n- Provide clear error messages\n- Document all options\n- Test across different project types\n\n## Related Documentation\n\n- [README.md](README.md) - User-facing documentation\n- [CHANGELOG.md](CHANGELOG.md) - Version history\n- [TOOLS.md](https://github.com/vintrepid/agents/blob/main/TOOLS.md) - Creating tools guide\n<!-- maestro_tool-end -->\n\n<!-- css_linter-start -->\n## css_linter usage\n# CssLinter Agent Guidelines\n\n## Overview\n\nCssLinter is a CSS analysis tool with pluggable strategies for scanning and reporting on CSS class usage patterns.\n\n## Usage\n\n### Installation\n\nAdd to your project's mix.exs:\n\n```elixir\ndef deps do\n  [\n    {:css_linter, github: \"vintrepid/css_linter\", only: [:dev]}\n  ]\nend\n```\n\n### Available Tasks\n\n#### `mix css_linter.analyze`\n\nAnalyzes CSS class usage in your project.\n\n**Options:**\n- `--strategy` - Analysis strategy to use (default: \"tailwind\")\n- `--output` - Output file path for JSON export\n- `--paths` - Comma-separated list of paths to scan (default: \"lib\")\n\n**Examples:**\n```bash\n# Analyze with Tailwind strategy\nmix css_linter.analyze --strategy tailwind\n\n# Export to JSON\nmix css_linter.analyze --strategy tailwind --output analysis.json\n\n# Scan specific paths\nmix css_linter.analyze --paths \"lib,priv/templates\"\n```\n\n## Strategies\n\n### Tailwind\n\nCategorizes Tailwind CSS classes into groups:\n- Layout (flex, grid, display)\n- Spacing (padding, margin, gap)\n- Sizing (width, height)\n- Typography (font, text)\n- Colors (bg, text, border colors)\n- Effects (shadow, opacity, blur)\n- DaisyUI Components\n- And more...\n\n### Custom Strategies\n\nCreate your own strategy by implementing the `CssLinter.Strategy` behavior:\n\n```elixir\ndefmodule MyApp.CustomStrategy do\n  @behaviour CssLinter.Strategy\n\n  def categorize(class_name) do\n    # Return category atom or nil\n  end\n  \n  def category_name(category) do\n    # Return human-readable category name\n  end\nend\n```\n\n## Development\n\n### Structure\n\n```\ncss_linter/\n├── lib/\n│   ├── css_linter/\n│   │   ├── application.ex\n│   │   ├── reporter.ex\n│   │   ├── scanner.ex\n│   │   ├── strategy.ex\n│   │   ├── strategies/\n│   │   │   └── tailwind.ex\n│   │   └── schema/\n│   ├── mix/\n│   │   └── tasks/\n│   │       └── css_linter.analyze.ex\n│   └── css_linter.ex\n├── test/\n├── mix.exs\n├── README.md\n├── INSTALLATION.md\n├── CHANGELOG.md\n└── AGENTS.md (this file)\n```\n\n### Adding New Strategies\n\n1. Create new file in `lib/css_linter/strategies/`\n2. Implement `CssLinter.Strategy` behavior\n3. Define `categorize/1` and `category_name/1` functions\n4. Register in strategy loader\n\n### Testing\n\n```bash\nmix test\n```\n\n### Release Process\n\n1. Update CHANGELOG.md\n2. Bump version in mix.exs\n3. Commit changes\n4. Tag release: `git tag v0.X.0`\n5. Push: `git push --tags`\n\n## Output Format\n\n### Console Report\n\n```\nCSS Analysis Report\n==================\n\nTotal Files Scanned: 45\nTotal Classes Found: 258 unique (1,191 occurrences)\n\nTop 10 Classes:\n  flex: 45 occurrences\n  gap-4: 32 occurrences\n  btn: 28 occurrences\n\nBy Category:\n  layout: 156 occurrences (45 unique)\n  spacing: 134 occurrences (38 unique)\n```\n\n### JSON Export\n\n```json\n{\n  \"summary\": {\n    \"total_files\": 45,\n    \"total_classes\": 258,\n    \"total_occurrences\": 1191\n  },\n  \"classes\": [\n    {\n      \"name\": \"flex\",\n      \"category\": \"layout\",\n      \"count\": 45,\n      \"files\": [...]\n    }\n  ]\n}\n```\n\n## Best Practices\n\n- Run analysis regularly to track CSS usage trends\n- Export JSON for historical tracking\n- Use with Tailwind purge configuration\n- Create custom strategies for project-specific patterns\n\n## Related Documentation\n\n- [README.md](README.md) - User-facing documentation\n- [INSTALLATION.md](INSTALLATION.md) - Installation guide\n- [CHANGELOG.md](CHANGELOG.md) - Version history\n- [TOOLS.md](https://github.com/vintrepid/agents/blob/main/TOOLS.md) - Creating tools guide\n\n## CSS Class Analysis & Cleanup\n\n### Running Analysis\n\n```bash\nmix css_linter.analyze --strategy tailwind --output analysis.json\n```\n\n### Cleanup Process\n\n1. Run analysis to identify high-usage patterns\n2. Extract repeated combinations (3+ occurrences) to semantic classes\n3. Create meaningful class names (`.page-section` not `.px-8-py-6`)\n4. Run analysis again to verify reduction\n5. Target: 20-26% reduction in unique classes\n\n### Where to Put Extracted Styles\n\n**Global CSS** (assets/css/app.css) - Application-wide patterns:\n```css\n.page-section {\n  @apply px-8 py-6;\n}\n```\n\n**Phoenix Components** (lib/*_web/components/) - Reusable UI patterns with markup\n\n**Keep in Template** - Simple layout and one-off adjustments\n\n### Integration Features\n\n**Web UI** (when mounted in app):\n- Visual class usage statistics\n- Category breakdowns\n- Sortable and searchable analysis results\n- Track cleanup progress over time\n<!-- css_linter-end -->\n\n<!-- live_table-start -->\n## live_table usage\n# LiveTable LLM Usage Guidelines\n\nThis document provides clear rules and patterns for AI assistants to help developers use the LiveTable library correctly. Follow these guidelines when generating code suggestions or helping with LiveTable implementation.\n\n## Core Principles\n\n### 1. Field Key Mapping is Critical\n**RULE**: Field keys in `fields()` function MUST match exactly with:\n- Schema field names (for simple tables)\n- Select clause keys (for custom queries)\n\n### 2. Two Primary Usage Patterns\nLiveTable supports exactly two patterns - choose the correct one:\n\n#### Pattern A: Simple Tables (Single Schema)\n```elixir\nuse LiveTable.LiveResource, schema: YourApp.Product\n```\n- Use when querying a single Ecto schema\n- Field keys must match schema field names exactly\n- No custom `data_provider` needed in `mount/3`\n\n#### Pattern B: Complex Tables (Custom Queries)\n```elixir\nuse LiveTable.LiveResource\n# Must define custom data provider in mount/3\n```\n- Use for joins, computed fields, or complex logic\n- Field keys must match select clause keys exactly\n- Requires custom data provider assignment\n\n## Critical Don'ts\n\n### DON'T Mix Patterns\n**NEVER** use `schema:` parameter with custom queries:\n```elixir\n# WRONG - Don't do this\nuse LiveTable.LiveResource, schema: User  # Remove this line\ndef mount(_params, _session, socket) do\n  socket = assign(socket, :data_provider, {MyApp.Users, :complex_query, []})\n  {:ok, socket}\nend\n```\n\n### DON'T Misalign Field Keys\n**NEVER** use field keys that don't match your data source:\n```elixir\n# WRONG - Field key doesn't match schema field\ndef fields do\n  [\n    user_name: %{label: \"Name\"}  # Schema field is 'name', not 'user_name'\n  ]\nend\n```\n\n### DON'T Forget Required Dependencies\n**NEVER** generate LiveTable code without the core dependency:\n```elixir\n# REQUIRED in mix.exs\n{:live_table, \"~> 0.3.1\"}\n# Add {:oban, \"~> 2.19\"} only if using export functionality\n```\n\n### DON'T Skip Asset Setup\n**NEVER** implement LiveTable without proper asset configuration\n\n## Required Setup Checklist\n\nWhen implementing with LiveTable, ALWAYS ensure:\n\n### 1. Dependencies\n```elixir\n# In mix.exs deps function\n{:live_table, \"~> 0.3.1\"}\n# Add {:oban, \"~> 2.19\"} only if using exports\n```\n\n### 2. Configuration\n```elixir\n# In config/config.exs\nconfig :live_table,\n  repo: YourApp.Repo,\n  pubsub: YourApp.PubSub\n\n# Add Oban config only if using exports\n# config :your_app, Oban,\n#   repo: YourApp.Repo,\n#   queues: [exports: 10]\n```\n\n### 3. JavaScript Assets\n```javascript\n// In assets/js/app.js\nimport hooks_default from \"../../deps/live_table/priv/static/live-table.js\";\n\nconst liveSocket = new LiveSocket(\"/live\", Socket, {\n  hooks: hooks_default,  // Required\n  // ... other config\n});\n```\n\n### 4. CSS Assets\n```css\n/* In assets/css/app.css */\n@source \"../../deps/live_table/lib\";\n@import \"../../deps/live_table/priv/static/live-table.css\";\n```\n\n## Implementation Templates\n\n### Template A: Simple Table (Single Schema)\n```elixir\ndefmodule YourAppWeb.ProductLive.Index do\n  use YourAppWeb, :live_view\n  use LiveTable.LiveResource, schema: YourApp.Product\n\n  def fields do\n    [\n      # Keys MUST match Product schema fields exactly\n      id: %{label: \"ID\", sortable: true},\n      name: %{label: \"Product Name\", sortable: true, searchable: true},\n      price: %{label: \"Price\", sortable: true},\n      stock_quantity: %{label: \"Stock\", sortable: true}\n    ]\n  end\n\n  def filters do\n    [\n      in_stock: Boolean.new(:stock_quantity, \"in_stock\", %{\n        label: \"In Stock Only\",\n        condition: dynamic([p], p.stock_quantity > 0)\n      })\n    ]\n  end\nend\n```\n\n### Template B: Complex Table (Custom Query)\n```elixir\ndefmodule YourAppWeb.OrderReportLive.Index do\n  use YourAppWeb, :live_view\n  use LiveTable.LiveResource  # NO schema parameter\n\n  def mount(_params, _session, socket) do\n    # REQUIRED: Assign custom data provider as {Module, Function, Arguments}\n    socket = assign(socket, :data_provider, {YourApp.Orders, :list_with_details, []})\n    {:ok, socket}\n  end\n\n  def fields do\n    [\n      # Keys MUST match select clause keys exactly\n      order_id: %{label: \"Order #\", sortable: true},\n      customer_name: %{label: \"Customer\", sortable: true, searchable: true},\n      total_amount: %{label: \"Total\", sortable: true}\n    ]\n  end\nend\n```\n\n```elixir\n# Corresponding context function\ndefmodule YourApp.Orders do\n  def list_with_details do\n    from o in Order,\n      join: c in Customer, on: o.customer_id == c.id,\n      select: %{\n        order_id: o.id,        # Field key must match this\n        customer_name: c.name, # Field key must match this\n        total_amount: o.total_amount\n      }\n  end\nend\n```\n\n## Field Configuration Rules\n\n### Basic Field Options\n```elixir\nfield_name: %{\n  label: \"Display Name\",      # Always provide\n  sortable: true,            # REQUIRED if field should be sortable\n  searchable: true,          # REQUIRED if field should be searchable\n}\n```\n\n### Custom Rendering with `renderer`\n\n**CRITICAL**: Use `renderer:` for custom cell formatting, not `component:` or `value:`.\n\nThe `renderer` function can receive either:\n- **function/1**: Receives only the cell value\n- **function/2**: Receives the cell value AND the full record/row\n\n```elixir\n# Function/1: Access only the cell value\nstatus: %{\n  label: \"Status\",\n  renderer: fn value -> \n    content_tag(:span, String.upcase(value), class: \"badge badge-#{value}\")\n  end\n}\n\n# Function/2: Access cell value AND full record for conditional rendering\npriority: %{\n  label: \"Priority\",\n  renderer: fn value, record ->\n    class = if record.urgent, do: \"text-red-600 font-bold\", else: \"text-gray-500\"\n    content_tag(:span, value, class: class)\n  end\n}\n\n# Using Phoenix.Component ~H sigil for complex markup\nuser_info: %{\n  label: \"User\",\n  renderer: fn _value, record ->\n    assigns = %{user: record}\n    ~H\"\"\"\n    <div class=\"flex items-center gap-2\">\n      <img src={@user.avatar_url} class=\"w-8 h-8 rounded-full\" />\n      <span>{@user.name}</span>\n    </div>\n    \"\"\"\n  end\n}\n```\n\n**Why function/2 is powerful**: Access to the full record lets you use data from ANY field, not just the current column's field. For example, showing a status badge that changes color based on a different field's value.\n\n### Association Sorting (Custom Queries Only)\n```elixir\n# When sorting by joined table fields\nproduct_name: %{\n  label: \"Product\",\n  sortable: true,\n  assoc: {:order_items, :name}  # Must match query alias and field\n}\n```\n\n## Filter Types\n\n### Boolean Filter\n```elixir\nBoolean.new(:field_name, \"param_name\", %{\n  label: \"Filter Label\",\n  condition: dynamic([alias], alias.field_name > 0)\n})\n```\n\n### Range Filter\n```elixir\nRange.new(:field_name, \"param_name\", %{\n  type: :number,  # or :date\n  label: \"Range Label\",\n  min: 0,\n  max: 1000\n})\n```\n\n### Select Filter\n```elixir\nSelect.new({:table_alias, :field_name}, \"param_name\", %{\n  label: \"Select Label\",\n  options: [\n    %{label: \"Display\", value: [\"actual_value\"]},\n    %{label: \"All Active\", value: [\"active\", \"pending\"]}\n  ]\n})\n```\n\n## Template Usage\n\n### Required Template Structure\n```elixir\n# In your .html.heex template\n<.live_table\n  fields={fields()}\n  filters={filters()}\n  options={@options}    # Required\n  streams={@streams}    # Required\n/>\n```\n\n## Common Error Patterns to Avoid\n\n### 1. Field Key Mismatch\n```elixir\n# Schema has 'email' field, but using wrong key\nemail_address: %{label: \"Email\"}  # Wrong\nemail: %{label: \"Email\"}          # Correct\n```\n\n### 2. Missing Data Provider for Custom Queries\n```elixir\n# Wrong - Custom query without data provider\nuse LiveTable.LiveResource\ndef fields do\n  [complex_field: %{label: \"Complex\"}]\nend\n# Missing: data_provider assignment in mount/3\n```\n\n### 3. Schema with Custom Query\n```elixir\n# Wrong - Using both schema and custom query\nuse LiveTable.LiveResource, schema: User\ndef mount(_params, _session, socket) do\n  socket = assign(socket, :data_provider, {App.Users, :custom_query, []})\nend\n```\n\n## Decision Tree for LLMs\n\nWhen helping with LiveTable implementation:\n\n1. **Is it a single table query?**\n   - YES → Use Pattern A (with `schema:`)\n   - NO → Use Pattern B (custom data provider)\n\n2. **Are there joins or computed fields?**\n   - YES → Must use Pattern B\n   - NO → Can use Pattern A\n\n3. **Do field keys match the data source?**\n   - Schema pattern → Keys match schema fields\n   - Custom pattern → Keys match select clause\n\n4. **Are all required assets configured?**\n   - Check deps, config, JS hooks, CSS imports\n\n5. **Is the template structure correct?**\n   - Verify `fields()`, `filters()`, `@options`, `@streams`\n\n## Quick Reference\n\n### Must-Have Functions\n- `fields()` - Always required\n- `filters()` - Optional but recommended\n\n### Must-Have Template Props\n- `fields={fields()}`\n- `filters={filters()}`\n- `options={@options}`\n- `streams={@streams}`\n\n### Must-Have Dependencies\n- `{:live_table, \"~> 0.3.1\"}` (always required)\n- `{:oban, \"~> 2.19\"}` (only if using exports)\n\n### Must-Have Config\n- LiveTable repo and pubsub config (always required)\n- Oban queue configuration (only if using exports)\n- JavaScript hooks import\n- CSS imports\n\nThis document ensures LLMs provide accurate, complete LiveTable implementations every time.\n<!-- live_table-end -->\n<!-- usage-rules-end -->\n",
    "purpose": "Library-specific patterns (Ash, Phoenix, Ecto, LiveView, etc.)"
  },
  "version": "2.0.0",
  "workflow": {
    "1_start_session": "Read this file (startup.json) - everything bundled here",
    "2_init_tracking": "mix bundles.track init maestro <branch> bootstrap",
    "3_check_task": "Read current_task.json for assigned work",
    "4_load_contextual": "If task involves another project, read their README. If task type known, load relevant bundle",
    "5_work": "Execute task, logging guideline usage as you go",
    "6_end_session": "mix bundles.track summary && mix session.capacity <used> 200000 && mix startup.build"
  }
}